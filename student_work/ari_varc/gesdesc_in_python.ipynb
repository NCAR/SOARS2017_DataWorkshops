{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev2 toc-item\"><a href=\"#Get-data-from-EOSDIS-the-Python-way-...\" data-toc-modified-id=\"Get-data-from-EOSDIS-the-Python-way-...-01\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Get data from EOSDIS the Python way ...</a></div><div class=\"lev3 toc-item\"><a href=\"#Making-a-request-for-NetCDF-data\" data-toc-modified-id=\"Making-a-request-for-NetCDF-data-011\"><span class=\"toc-item-num\">0.1.1&nbsp;&nbsp;</span>Making a request for NetCDF data</a></div><div class=\"lev3 toc-item\"><a href=\"#[aside]-Huh?--What-is-that-URL-from???\" data-toc-modified-id=\"[aside]-Huh?--What-is-that-URL-from???-012\"><span class=\"toc-item-num\">0.1.2&nbsp;&nbsp;</span>[aside] Huh?  What is that URL from???</a></div><div class=\"lev3 toc-item\"><a href=\"#Saving-the-data-from-the-request\" data-toc-modified-id=\"Saving-the-data-from-the-request-013\"><span class=\"toc-item-num\">0.1.3&nbsp;&nbsp;</span>Saving the data from the request</a></div><div class=\"lev3 toc-item\"><a href=\"#Yay!-We-have-a-NetCDF-file-...\" data-toc-modified-id=\"Yay!-We-have-a-NetCDF-file-...-014\"><span class=\"toc-item-num\">0.1.4&nbsp;&nbsp;</span>Yay! We have a NetCDF file ...</a></div><div class=\"lev3 toc-item\"><a href=\"#Using-NetCDF-in-Python\" data-toc-modified-id=\"Using-NetCDF-in-Python-015\"><span class=\"toc-item-num\">0.1.5&nbsp;&nbsp;</span>Using NetCDF in Python</a></div><div class=\"lev3 toc-item\"><a href=\"#Back-on-track:-Iterating-over-a-large-number-of-files-...\" data-toc-modified-id=\"Back-on-track:-Iterating-over-a-large-number-of-files-...-016\"><span class=\"toc-item-num\">0.1.6&nbsp;&nbsp;</span>Back on track: Iterating over a large number of files ...</a></div><div class=\"lev3 toc-item\"><a href=\"#PyDAP-Solution\" data-toc-modified-id=\"PyDAP-Solution-017\"><span class=\"toc-item-num\">0.1.7&nbsp;&nbsp;</span>PyDAP Solution</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from EOSDIS the Python way ...\n",
    "\n",
    "We will be using Python to get the data and it will make life easy in the future.\n",
    "\n",
    "The instructions in this notebook (a variant of them at least), is found on NASAs site [here](https://disc.gsfc.nasa.gov/registration/registration-for-data-access#python).\n",
    "\n",
    "**IMPORTANT NOTES:**\n",
    "* follow the instructions [here](https://disc.gsfc.nasa.gov/registration/authorizing-gesdisc-data-access-in-earthdata_login) to AUTHORIZE _GESDISC_ ACCESS FOR YOUR ACCOUNT, OTHERWISE **THIS WILL NOT WORK**\n",
    "* make sure you are using the correct username and password for your account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = '' # your GES DISC username\n",
    "password = '' # your GES DISC password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of GES DISC silliness is required, but cut and paste verbatim. The how/why of this trickery can be found [here](https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+Python).  Under normal circumstances and with other services, this step will not be necessary or look a bit differently.  This is a solution that works well with the GES DISC system, but likely not others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from urllib.request import urlopen\n",
    "from http import cookiejar\n",
    "\n",
    "password_manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "password_manager.add_password(None, \"https://urs.earthdata.nasa.gov\", username, password)\n",
    "cookie_jar = cookiejar.CookieJar()\n",
    "\n",
    "opener = request.build_opener(\n",
    "    request.HTTPBasicAuthHandler(password_manager),\n",
    "    #urllib2.HTTPHandler(debuglevel=1),    # Uncomment these two lines to see\n",
    "    #urllib2.HTTPSHandler(debuglevel=1),   # details of the requests/responses\n",
    "    request.HTTPCookieProcessor(cookie_jar))\n",
    "request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a request for NetCDF data\n",
    "The template for making a request for data looks like this:\n",
    "\n",
    "1. set the URL of the data you want\n",
    "2. open a request with url\n",
    "3. process the response of that request\n",
    "\n",
    "Here is the code that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url  = 'http://disc2.gesdisc.eosdis.nasa.gov/opendap/TRMM_L3/TRMM_3B43.7/2015/3B43.20151201.7.HDF.nc'\n",
    "req  = request.Request(url)\n",
    "resp = urlopen(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [aside] Huh?  What is that URL from???\n",
    "\n",
    "If you go into a download screen and hover over the NetCDF link, you'll see the URL that is above -- `http://disc2.[...]./opendap/TRMM_L3/[...]`.\n",
    "\n",
    "![](./opera_2017-06-15_13-01-37.png)\n",
    "This is very important to pay attention to, because we'll need it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data from the request\n",
    "\n",
    "Saving the data is now like you would expect in normal Python code ... we'll rename the file to `sample_file.nc` and write it to the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"sample_file.nc\",\"wb\") as fo:\n",
    "    fo.write(resp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yay! We have a NetCDF file ...\n",
    "\n",
    "We have a file that we can use, so lets go see what's in it!\n",
    "\n",
    "To proceed, you will need to make sure you have the `netCDF4` library.  \n",
    "\n",
    "**TESTING YOUR NETCDF4**\n",
    "\n",
    "* in a Jupyter Notebook, type \n",
    "```python\n",
    "from netCDF4 import *\n",
    "```\n",
    "* if you get an error follow the directions below\n",
    "\n",
    "** INSTALLING NETCDF4**\n",
    "\n",
    "* open your terminal\n",
    "* type \n",
    "```bash\n",
    "conda install netcdf\n",
    "```\n",
    "* type Y a few times only when prompted\n",
    "* test again with the instructions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NetCDF in Python\n",
    "\n",
    "This notebook doesn't go into the details of netCDF in Python, so if you need to learn how to do complex things with it, please [see the full docs here](https://unidata.github.io/netcdf4-python/).\n",
    "\n",
    "Instead we'll poke around to make sure the file is as we think it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT NETCDF AND LOAD A FILE LIKE THIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "rootgrp = Dataset(\"sample_file.nc\", \"r\", format=\"NETCDF4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POKE AROUND THE VARIABLES OF THIS FILE LIKE THIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('precipitation', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 precipitation(nlon, nlat)\n",
       "                  units: mm/hr\n",
       "                  coordinates: nlon nlat\n",
       "                  _FillValue: -9999.9\n",
       "              unlimited dimensions: \n",
       "              current shape = (1440, 400)\n",
       "              filling off),\n",
       "             ('relativeError', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 relativeError(nlon, nlat)\n",
       "                  units: mm/hr\n",
       "                  coordinates: nlon nlat\n",
       "                  _FillValue: -9999.9\n",
       "              unlimited dimensions: \n",
       "              current shape = (1440, 400)\n",
       "              filling off),\n",
       "             ('gaugeRelativeWeighting', <class 'netCDF4._netCDF4.Variable'>\n",
       "              int32 gaugeRelativeWeighting(nlon, nlat)\n",
       "                  units: percent\n",
       "                  coordinates: nlon nlat\n",
       "              unlimited dimensions: \n",
       "              current shape = (1440, 400)\n",
       "              filling off),\n",
       "             ('nlon', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 nlon(nlon)\n",
       "                  long_name: longitude\n",
       "                  standard_name: longitude\n",
       "                  units: degrees_east\n",
       "              unlimited dimensions: \n",
       "              current shape = (1440,)\n",
       "              filling off),\n",
       "             ('nlat', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 nlat(nlat)\n",
       "                  long_name: latitude\n",
       "                  standard_name: latitude\n",
       "                  units: degrees_north\n",
       "              unlimited dimensions: \n",
       "              current shape = (400,)\n",
       "              filling off)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 400)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LETS LOOK AT PRECIPITATION'S SHAPE AND PLAY A BIT ...\n",
    "rootgrp.variables['precipitation'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09600807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.variables['precipitation'][1439,399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.variables['nlon'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-179.875, -179.625, -179.375, ...,  179.375,  179.625,  179.875], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.variables['nlon'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-49.875, -49.625, -49.375, -49.125, -48.875, -48.625, -48.375,\n",
       "       -48.125, -47.875, -47.625, -47.375, -47.125, -46.875, -46.625,\n",
       "       -46.375, -46.125, -45.875, -45.625, -45.375, -45.125, -44.875,\n",
       "       -44.625, -44.375, -44.125, -43.875, -43.625, -43.375, -43.125,\n",
       "       -42.875, -42.625, -42.375, -42.125, -41.875, -41.625, -41.375,\n",
       "       -41.125, -40.875, -40.625, -40.375, -40.125, -39.875, -39.625,\n",
       "       -39.375, -39.125, -38.875, -38.625, -38.375, -38.125, -37.875,\n",
       "       -37.625, -37.375, -37.125, -36.875, -36.625, -36.375, -36.125,\n",
       "       -35.875, -35.625, -35.375, -35.125, -34.875, -34.625, -34.375,\n",
       "       -34.125, -33.875, -33.625, -33.375, -33.125, -32.875, -32.625,\n",
       "       -32.375, -32.125, -31.875, -31.625, -31.375, -31.125, -30.875,\n",
       "       -30.625, -30.375, -30.125, -29.875, -29.625, -29.375, -29.125,\n",
       "       -28.875, -28.625, -28.375, -28.125, -27.875, -27.625, -27.375,\n",
       "       -27.125, -26.875, -26.625, -26.375, -26.125, -25.875, -25.625,\n",
       "       -25.375, -25.125, -24.875, -24.625, -24.375, -24.125, -23.875,\n",
       "       -23.625, -23.375, -23.125, -22.875, -22.625, -22.375, -22.125,\n",
       "       -21.875, -21.625, -21.375, -21.125, -20.875, -20.625, -20.375,\n",
       "       -20.125, -19.875, -19.625, -19.375, -19.125, -18.875, -18.625,\n",
       "       -18.375, -18.125, -17.875, -17.625, -17.375, -17.125, -16.875,\n",
       "       -16.625, -16.375, -16.125, -15.875, -15.625, -15.375, -15.125,\n",
       "       -14.875, -14.625, -14.375, -14.125, -13.875, -13.625, -13.375,\n",
       "       -13.125, -12.875, -12.625, -12.375, -12.125, -11.875, -11.625,\n",
       "       -11.375, -11.125, -10.875, -10.625, -10.375, -10.125,  -9.875,\n",
       "        -9.625,  -9.375,  -9.125,  -8.875,  -8.625,  -8.375,  -8.125,\n",
       "        -7.875,  -7.625,  -7.375,  -7.125,  -6.875,  -6.625,  -6.375,\n",
       "        -6.125,  -5.875,  -5.625,  -5.375,  -5.125,  -4.875,  -4.625,\n",
       "        -4.375,  -4.125,  -3.875,  -3.625,  -3.375,  -3.125,  -2.875,\n",
       "        -2.625,  -2.375,  -2.125,  -1.875,  -1.625,  -1.375,  -1.125,\n",
       "        -0.875,  -0.625,  -0.375,  -0.125,   0.125,   0.375,   0.625,\n",
       "         0.875,   1.125,   1.375,   1.625,   1.875,   2.125,   2.375,\n",
       "         2.625,   2.875,   3.125,   3.375,   3.625,   3.875,   4.125,\n",
       "         4.375,   4.625,   4.875,   5.125,   5.375,   5.625,   5.875,\n",
       "         6.125,   6.375,   6.625,   6.875,   7.125,   7.375,   7.625,\n",
       "         7.875,   8.125,   8.375,   8.625,   8.875,   9.125,   9.375,\n",
       "         9.625,   9.875,  10.125,  10.375,  10.625,  10.875,  11.125,\n",
       "        11.375,  11.625,  11.875,  12.125,  12.375,  12.625,  12.875,\n",
       "        13.125,  13.375,  13.625,  13.875,  14.125,  14.375,  14.625,\n",
       "        14.875,  15.125,  15.375,  15.625,  15.875,  16.125,  16.375,\n",
       "        16.625,  16.875,  17.125,  17.375,  17.625,  17.875,  18.125,\n",
       "        18.375,  18.625,  18.875,  19.125,  19.375,  19.625,  19.875,\n",
       "        20.125,  20.375,  20.625,  20.875,  21.125,  21.375,  21.625,\n",
       "        21.875,  22.125,  22.375,  22.625,  22.875,  23.125,  23.375,\n",
       "        23.625,  23.875,  24.125,  24.375,  24.625,  24.875,  25.125,\n",
       "        25.375,  25.625,  25.875,  26.125,  26.375,  26.625,  26.875,\n",
       "        27.125,  27.375,  27.625,  27.875,  28.125,  28.375,  28.625,\n",
       "        28.875,  29.125,  29.375,  29.625,  29.875,  30.125,  30.375,\n",
       "        30.625,  30.875,  31.125,  31.375,  31.625,  31.875,  32.125,\n",
       "        32.375,  32.625,  32.875,  33.125,  33.375,  33.625,  33.875,\n",
       "        34.125,  34.375,  34.625,  34.875,  35.125,  35.375,  35.625,\n",
       "        35.875,  36.125,  36.375,  36.625,  36.875,  37.125,  37.375,\n",
       "        37.625,  37.875,  38.125,  38.375,  38.625,  38.875,  39.125,\n",
       "        39.375,  39.625,  39.875,  40.125,  40.375,  40.625,  40.875,\n",
       "        41.125,  41.375,  41.625,  41.875,  42.125,  42.375,  42.625,\n",
       "        42.875,  43.125,  43.375,  43.625,  43.875,  44.125,  44.375,\n",
       "        44.625,  44.875,  45.125,  45.375,  45.625,  45.875,  46.125,\n",
       "        46.375,  46.625,  46.875,  47.125,  47.375,  47.625,  47.875,\n",
       "        48.125,  48.375,  48.625,  48.875,  49.125,  49.375,  49.625,\n",
       "        49.875], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.variables['nlat'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-147.375\n",
      "-47.375\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.variables['nlon'][130])\n",
    "print(rootgrp.variables['nlat'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0950806\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.variables['precipitation'][130,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back on track: Iterating over a large number of files ...\n",
    "\n",
    "Let's say we put a bunch of files in our cart:\n",
    "\n",
    "![](./opera_2017-06-15_12-22-04.png)\n",
    "\n",
    "We can proceed to get the URLs by checking out and can list all the URLs using the `Download URL List (Data)` option:\n",
    "\n",
    "![](./opera_2017-06-15_12-24-04.png)\n",
    "\n",
    "and you will get a list of files in your cart like this:\n",
    "\n",
    "![](./opera_2017-06-15_12-33-19.png)\n",
    "\n",
    "Copy these using cut and paste and store these into a file -- we'll call ours `data_sample.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will process the contents of the file we just saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./data_sample.txt\") as f_ds:\n",
    "    urls = [l.strip() for l in f_ds.readlines()]  \n",
    "    # readlines() includes the \\n at the end of the line \n",
    "    # so this cleans it up for us in one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you notice, all the URLs we have (at least for the HDF files) is separated by `\\\\`.  Unfortunately, with GES DISC the URL to get the netCDF file, we need a different URL and we also need to append the filename with `.nc` for netCDF.\n",
    "\n",
    "I'm not clear on why the URLs are different (other than they are different formats and there is an indication that [OpenDAP](https://www.opendap.org) is at play on their side), but the URL we need to obtain the data is only different by a small amount:\n",
    "\n",
    "instead of \n",
    "\n",
    "* http://disc2.gesdisc.eosdis.nasa.gov/data//TRMM_L3/TRMM_3B43.7/1998/3B43.19980801.7.HDF\n",
    "\n",
    "we'll use\n",
    "\n",
    "* http://disc2.gesdisc.eosdis.nasa.gov/opendap/TRMM_L3/TRMM_3B43.7/1998/3B43.19980801.7.HDF.nc\n",
    "\n",
    "\n",
    "Notice `data` is replaced by `opendap` ... everything else is the same.\n",
    "\n",
    "One way to do this is to use `split()` on `\\\\`.  Another is to use `replace()`.  We'll use replace and I'll leave is as fun to use `replace()` as shown in the section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................."
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    local_filename = url.split('/')[-1]\n",
    "    url = url.replace('/data','/opendap').replace('.HDF', '.HDF.nc')\n",
    "    \n",
    "    # make the request to the server\n",
    "    req  = request.Request(url)\n",
    "    resp = urlopen(req)\n",
    "    \n",
    "    with open(local_filename, \"wb\") as fo:\n",
    "        fo.write(resp.read())\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USING SPLIT INSTEAD OF REPLACE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http:',\n",
       " 'disc2.gesdisc.eosdis.nasa.gov/data',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20001201.7A.HDF']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[0].split('//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_urls = [url.split('//')[-1] for url in urls if url.endswith('.HDF')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRMM_L3/TRMM_3B43.7/2000/3B43.20001201.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20001101.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20001001.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000901.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000801.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000701.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000601.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000501.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000401.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000301.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000201.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/2000/3B43.20000101.7A.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19991201.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19991101.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19991001.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990901.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990801.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990701.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990601.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990501.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990401.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990301.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990201.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1999/3B43.19990101.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19981201.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19981101.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19981001.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980901.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980801.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980701.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980601.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980501.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980401.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980301.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980201.7.HDF',\n",
       " 'TRMM_L3/TRMM_3B43.7/1998/3B43.19980101.7.HDF']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................."
     ]
    }
   ],
   "source": [
    "gesdisc_base_dap_url = 'http://disc2.gesdisc.eosdis.nasa.gov/opendap/'\n",
    "for url in file_urls:\n",
    "    gesdisc_url = \"{}/{}.nc\".format(gesdisc_base_dap_url, url)\n",
    "    \n",
    "    # grab the local filename\n",
    "    local_filename = url.split('/')[-1]\n",
    "    \n",
    "    # make the request to the server\n",
    "    req  = request.Request(gesdisc_url)\n",
    "    resp = urlopen(req)\n",
    "    \n",
    "    with open(local_filename, \"wb\") as fo:\n",
    "        fo.write(resp.read())\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyDAP Solution\n",
    "\n",
    "[PyDAP](http://www.pydap.org/en/latest/#) is another tool you may try to use to get the job done, though I was unable to get it to work as easily as the solution above.\n",
    "\n",
    "To get PyDAP, you will need to first do the following and install the `pydap` package in conda:\n",
    "\n",
    "```bash\n",
    "conda install pydap\n",
    "```\n",
    "\n",
    "Once this is done (you may have to hit Y) a few times through the installer."
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "student_work/ari_vc/gesdesc_in_python.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
